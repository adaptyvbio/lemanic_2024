{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's install the requirements, if you haven't done that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to generate [ESM-2](https://github.com/facebookresearch/esm) protein language model embeddings for the heavy chain and average over the whole sequence. Other potential approaches could be to utilise the light chain as well and/or only embed or average over the CDR regions. You could also try other models, such as [ProtBert](https://github.com/nadavbra/protein_bert) or [ProtTrans](https://github.com/agemagician/ProtTrans).\n",
    "\n",
    "You can download the embeddings we generated here by uncommenting and running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install awscli\n",
    "# !aws s3 sync s3://lemanic-adaptyv-2024/embeddings embeddings --no-sign-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32  # Make the batch size smaller if you run out of memory\n",
    "\n",
    "# model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "# batch_converter = alphabet.get_batch_converter()\n",
    "# device = (\n",
    "#     \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )  # Running this on GPU will be significantly faster\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# if not os.path.exists(\"embeddings\"):\n",
    "#     os.makedirs(\"embeddings\")\n",
    "    \n",
    "# for csv_file in [\n",
    "#     \"literature_test.csv\",\n",
    "#     \"literature_train.csv\",\n",
    "#     \"experiment_test.csv\",\n",
    "#     \"experiment_train.csv\",\n",
    "# ]:\n",
    "#     df = pd.read_csv(os.path.join(\"data\", csv_file))\n",
    "#     name = csv_file[:-4]\n",
    "#     if not os.path.exists(os.path.join(\"embeddings\", name)):\n",
    "#         os.makedirs(os.path.join(\"embeddings\", name))\n",
    "#     data = [(index, row[\"VHorVHH\"]) for index, row in df.iterrows()]\n",
    "#     data_len = len(data)\n",
    "#     index_range = list(range(0, data_len, BATCH_SIZE))\n",
    "#     for i in tqdm(index_range):\n",
    "#         batch_labels, batch_strs, batch_tokens = batch_converter(\n",
    "#             data[i : min(data_len, i + BATCH_SIZE)]\n",
    "#         )\n",
    "#         batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             results = model(\n",
    "#                 batch_tokens.to(device=device), repr_layers=[33], return_contacts=True\n",
    "#             )\n",
    "#         token_representations = results[\"representations\"][33].cpu().numpy()\n",
    "\n",
    "#         for seq_index, (tokens_len, label) in enumerate(zip(batch_lens, batch_labels)):\n",
    "#             with open(os.path.join(\"embeddings\", name, f\"{label}.pickle\"), \"wb\") as f:\n",
    "#                 pickle.dump(\n",
    "#                     token_representations[seq_index, 1 : tokens_len - 1].mean(0), f\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are generating the embeddings, restart the kernel before moving on to the next cells to free up the RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's tackle the dataset that simulates learning on literature, with more positive samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/literature_train.csv\")\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, row in df_train.iterrows():\n",
    "    with open(os.path.join(\"embeddings\", \"literature_train\", f\"{i}.pickle\"), \"rb\") as f:\n",
    "        emb = pickle.load(f)\n",
    "    X_train.append(emb)\n",
    "    y_train.append(int(row[\"Binds\"]))\n",
    "X_train = np.stack(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "df_test = pd.read_csv(\"data/literature_test.csv\")\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i, row in df_test.iterrows():\n",
    "    with open(os.path.join(\"embeddings\", \"literature_test\", f\"{i}.pickle\"), \"rb\") as f:\n",
    "        emb = pickle.load(f)\n",
    "    X_test.append(emb)\n",
    "    y_test.append(int(row[\"Binds\"]))\n",
    "X_test = np.stack(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a simple random forest classifier on the heavy chain embeddings, with SMOTE resampling to balance the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-random F1: 0.35 ± 0.01\n",
      "Random F1: 0.24 ± 0.00\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=128)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "random_f1 = []\n",
    "non_random_f1 = []\n",
    "for seed in range(5):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    non_random_f1.append(f1_score(y_test, predictions))\n",
    "    random_f1_ = []\n",
    "    for _ in range(100):\n",
    "        np.random.shuffle(predictions)\n",
    "        random_f1_.append(f1_score(y_test, predictions))\n",
    "    random_f1.append(np.mean(random_f1_))\n",
    "print(f\"Non-random F1: {np.mean(non_random_f1):.2f} ± {np.std(non_random_f1):.2f}\")\n",
    "print(f\"Random F1: {np.mean(random_f1):.2f} ± {np.std(random_f1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the result with a random baseline and see that the model is making meaningful predictions (although they can certainly be improved)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to the experiment simulation dataset, which is more similar to the test set. We will train the same model on the heavy chain embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/experiment_train.csv\")\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, row in df_train.iterrows():\n",
    "    with open(os.path.join(\"embeddings\", \"literature_train\", f\"{i}.pickle\"), \"rb\") as f:\n",
    "        emb = pickle.load(f)\n",
    "    X_train.append(emb)\n",
    "    y_train.append(int(row[\"Binds\"]))\n",
    "X_train = np.stack(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "df_test = pd.read_csv(\"data/experiment_test.csv\")\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i, row in df_test.iterrows():\n",
    "    with open(os.path.join(\"embeddings\", \"literature_test\", f\"{i}.pickle\"), \"rb\") as f:\n",
    "        emb = pickle.load(f)\n",
    "    X_test.append(emb)\n",
    "    y_test.append(int(row[\"Binds\"]))\n",
    "X_test = np.stack(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-random F1: 0.27 ± 0.02\n",
      "Random F1: 0.25 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=128)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "random_f1 = []\n",
    "non_random_f1 = []\n",
    "for seed in range(5):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    non_random_f1.append(f1_score(y_test, predictions))\n",
    "    random_f1_ = []\n",
    "    for _ in range(100):\n",
    "        np.random.shuffle(predictions)\n",
    "        random_f1_.append(f1_score(y_test, predictions))\n",
    "    random_f1.append(np.mean(random_f1_))\n",
    "print(f\"Non-random F1: {np.mean(non_random_f1):.2f} ± {np.std(non_random_f1):.2f}\")\n",
    "print(f\"Random F1: {np.mean(random_f1):.2f} ± {np.std(random_f1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the same naive method leads to results that are not better than chance. This might be because the embeddings are not capturing the relevant information, or because more sophisticated methods for battling class imbalance are required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lemanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
